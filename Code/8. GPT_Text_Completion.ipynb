{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["7EYqp1EDtDqk"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CaaXByxrIOc","executionInfo":{"status":"ok","timestamp":1701351441155,"user_tz":-540,"elapsed":17371,"user":{"displayName":"허윤빈","userId":"08770990058347312512"}},"outputId":"3ce4625f-adfa-49e1-e8a5-2c7648f71127"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#!pip install -U torch transformers tokenizers accelerate safetensors"],"metadata":{"id":"WvKcRlC2rJIc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","import re\n","import os\n","os.chdir('/content/drive/MyDrive/응용통계학과 공모전')\n","\n","from matplotlib import rc\n","import matplotlib.font_manager as fm\n","# 디렉토리 및 파일 이름에 맞추어 변경\n","font_location ='./NanumGothic.ttf'\n","# 폰트 설정\n","rc('font', family='NanumGothic')\n","plt.rcParams['axes.unicode_minus'] = False  # 마이너스 기호 깨짐 방지"],"metadata":{"id":"9NiesoEVhaJ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 요약\n","1. 직무별 기술스택 그래프를 불러온다.\n","2. 확인하고 싶은 기술스택 그래프를 전역변수로 설정한다.\n","3. 사용자의 기술스택이 그래프 내에 존재하는지 확인한 뒤, 인접한 노드들을 gpt_chat_completion에 전달한 input으로 가져온다. 이때, 기술스택은 여러개가 전달될 수 있으므로 중복되는 기술스택은 제거한 뒤 input으로 가져온다.\n","4. 사용자의 기술스택이 그래프 내에 존재하지 않는다면, 그래프 내의 가중치가 가장 높은 상위 n개 노드를 가져와 input으로 가져온다.\n","5. role: system을 작성하며 단어를 바탕으로 문장을 출력하도록 프롬프트 엔지니어링을 진행한다.\n","6. 출력 결과를 확인한다."],"metadata":{"id":"klv5aMxMjrv4"}},{"cell_type":"code","source":["import numpy as np\n","import networkx as nx\n","import operator\n","\n","from glob import glob\n","\n","# #직무별 기술스택 그래프 불러오기\n","# for g in glob('data/text_network/*.gml'):\n","#     print(g.split('/')[-1].replace('_gpt.gml',''))\n","#     globals()[g.split('/')[-1].replace('_gpt.gml','')] = nx.read_gml(g)\n","\n","#직무별 기술스택 그래프 불러오기\n","ML_graph = nx.read_gml(\"ML_graph_gpt.gml\")\n","DE_graph = nx.read_gml(\"DE_graph_gpt.gml\")\n","DSC_graph = nx.read_gml(\"DSC_graph_gpt.gml\")\n","BD_graph = nx.read_gml(\"BD_graph_gpt.gml\")\n","BI_graph = nx.read_gml(\"BI_graph_gpt.gml\")\n","DBA_graph = nx.read_gml(\"DBA_graph_gpt.gml\")\n","\n","def get_neighbors(target, graph):\n","  try:\n","    connected_nodes = list(graph.neighbors(target))\n","  except:\n","    connected_nodes = []\n","\n","  # 연결된 노드 중에서 가중치가 높은 상위 4개 노드 출력\n","  if connected_nodes:\n","      weights = [(node, graph[target][node]['weight']) for node in connected_nodes]\n","      sorted_weights = sorted(weights, key=operator.itemgetter(1), reverse=True)\n","      print(sorted_weights[:4])\n","      return sorted_weights[:4]\n","\n","  else:\n","      print(f\"No nodes connected to '{target}'.\")\n","      return -1\n","\n","#만약 사용자 input이 graph내에 하나도 없을 경우 weight가 높은 순으로 node를 반환\n","def get_sorted_nodes(graph):\n","\n","  edge_weights = nx.get_edge_attributes(graph, 'weight')\n","\n","  # 가중치가 높은 순으로 노드 정렬\n","  sorted_nodes = sorted(edge_weights, key=edge_weights.get, reverse=True)\n","\n","  return sorted_nodes[:10]"],"metadata":{"id":"0ju7ahizeu6M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Ko-Alpaca 모델을 이용 (채택 x)"],"metadata":{"id":"7EYqp1EDtDqk"}},{"cell_type":"code","source":["import torch\n","from transformers import pipeline, AutoModelForCausalLM\n","\n","MODEL = 'beomi/KoAlpaca-Polyglot-5.8B'\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL,\n","    torch_dtype=torch.float16,\n","    low_cpu_mem_usage=True,\n",").to(device=f\"cuda\", non_blocking=True)\n","model.eval()\n","\n","pipe = pipeline(\n","    'text-generation',\n","    model=model,\n","    tokenizer=MODEL,\n","    device='cuda'\n",")\n","\n","def ask(x, context='', is_input_full=False):\n","    ans = pipe(\n","        f\"### 질문: {x}\\n\\n### 맥락: {context}\\n\\n### 답변:\" if context else f\"### 질문: {x}\\n\\n### 답변:\",\n","        do_sample=True,\n","        max_new_tokens=512,\n","        temperature=0.7,\n","        top_p=0.9,\n","        return_full_text=False,\n","        eos_token_id=2,\n","    )\n","    print(ans[0]['generated_text'])\n","\n","ask(\"딥러닝이 뭐야?\")\n","# 딥러닝은 인공신경망을 통해 입력과 출력 사이의 복잡한 관계를 학습하는 머신러닝의 한 분야입니다. 이 기술은 컴퓨터가 인간의 학습 능력과 유사한 방식으로 패턴을 학습하도록 하며, 인간의 개입 없이도 데이터를 처리할 수 있는 기술입니다. 최근에는 딥러닝을 활용한 인공지능 애플리케이션이 많이 개발되고 있습니다. 예를 들어, 의료 진단 애플리케이션에서는 딥러닝 기술을 활용하여 환자의 특징을 파악하고, 이를 통해 빠르고 정확한 진단을 내리는 데 사용됩니다. 또한, 금융 분야에서는 딥러닝 기술을 활용하여 주가 예측 모형을 학습하는 데 사용되기도 합니다."],"metadata":{"id":"F1E_koZIrZsS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# OPENAI gpt-3.5 turbo모델 이용"],"metadata":{"id":"Lh-Dd_NFv9rE"}},{"cell_type":"code","source":["!pip install openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tQMik221pA1v","executionInfo":{"status":"ok","timestamp":1701351460292,"user_tz":-540,"elapsed":9155,"user":{"displayName":"허윤빈","userId":"08770990058347312512"}},"outputId":"443d4673-e51d-4d7b-8b6a-b3b1baa74e57"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai\n","  Downloading openai-1.3.6-py3-none-any.whl (220 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n","Collecting httpx<1,>=0.23.0 (from openai)\n","  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n","Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n","Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: h11, httpcore, httpx, openai\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.6\n"]}]},{"cell_type":"code","source":["import openai\n","\n","# OpenAI API 키 설정 (자신의 API 키로 대체해야 함)\n","api_key = ''\n","openai.api_key = api_key\n","\n","# GPT-3 API 호출 함수\n","def generate_text(skill):\n","    response = openai.chat.completions.create(\n","        model=\"gpt-3.5-turbo\",\n","        messages= [\n","            {\"role\": \"system\", \"content\": \"당신은 입력된 단어를 이용해서, 사용자에게 관련된 역량을 길러보라고 알려주는 machine입니다.\"},\n","            {\"role\": \"system\", \"content\": \"단어에 대한 설명은 생략하고, 짧은 문장으로만 답변을 제시하세요.\"},\n","            {\"role\": \"system\", \"content\": \"입력받은 단어가 최대한 들어가도록 문장을 구성하세요.\"},\n","            {\"role\": \"system\", \"content\": \"만약 React와 같이 기술스택과 관련한 단어를 입력받았다면, 당신의 답변은 'React 프레임워크 기술을 쌓아보세요.'와 같은 문장이어야 합니다.\"},\n","            {\"role\": \"system\", \"content\": \"학위와 관련된 단어를 입력받았다면, 당신의 답변은 '전문적인 지식이 요구되는 분야이니, 석사 이상의 학위 취득을 추천드립니다.'와 같은 문장이어야 합니다. \"},\n","            {\"role\": \"system\", \"content\": \"경험 혹은 역량과 관련된 단어라면, 관련된 경험을 쌓아보라는 문장을 제시해야 합니다.\"},\n","            {\"role\": \"system\", \"content\": \"한글로 답변하세요.\"},\n","            {\"role\": \"user\", \"content\" : skill}\n","        ],\n","        temperature=0.5\n","    )\n","    return response.choices[0].message.content"],"metadata":{"id":"jnd9vZSBwAXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## user에게 input으로 기술스택 받았다고 하자"],"metadata":{"id":"0br52T-KhjCq"}},{"cell_type":"code","source":["skill_set = input(\"사용 가능하신 기술스택을 나열해 주세요. ex) python, sql ... \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wM6yNlsK2wIr","executionInfo":{"status":"ok","timestamp":1701356007507,"user_tz":-540,"elapsed":4583,"user":{"displayName":"허윤빈","userId":"08770990058347312512"}},"outputId":"010f0467-1164-4454-ee3a-8794bbaf5542"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["사용 가능하신 기술스택을 나열해 주세요. ex) python, sql ... python, sql\n"]}]},{"cell_type":"code","source":["#전역변수\n","GRAPH = ML_graph\n","\n","#주변 노드가 담길 list\n","neighbor_list = []\n","extracted_nodes = []\n","\n","#input의 주변 노드를 구함\n","for skill in skill_set.split(','):\n","  tmp = get_neighbors(skill.strip(), GRAPH)\n","  if tmp != -1:\n","    neighbor_list.append(tmp)\n","\n","#주변 노드를 담는 리스트가 비어있지 않으면\n","if neighbor_list:\n","  # gpt 모델에 전달할 기술스택 리스트를 뽑는 과정\n","  for i in range(len(neighbor_list)):\n","    for j in range(4):\n","      extracted_nodes.append(neighbor_list[i][j][0])\n","\n","\n","#사용자의 스킬이 그래프 내에 존재하지 않아서 주변 노드 리스트가 비어있는 경우\n","else:\n","  rank = get_sorted_nodes(GRAPH)\n","\n","  for i in range(len(rank)):\n","    extracted_nodes.append(rank[i][0])\n","    extracted_nodes.append(rank[i][1])\n","\n","# extracted_nodes에서 사용자에게 인풋으로 받은 기술스택은 추천하지 않도록 제거\n","skill_set_list = [value.strip() for value in skill_set.split(',')]\n","extracted_nodes = [value for value in extracted_nodes if value not in skill_set_list]\n","print(skill_set_list)\n","print(extracted_nodes)\n","\n","gpt_input = \",\".join(list(set(extracted_nodes)))\n","print(gpt_input)\n","#gpt 답변\n","generated_sentence = generate_text(gpt_input)\n","\n","# 문장을 점(.)으로 나누기\n","sentences = generated_sentence.split('.')\n","\n","# 공백을 제거하고 문장을 다시 조립\n","output = \"\\n\".join(sentence.strip() + '.' for sentence in sentences if sentence)\n","\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uHOr_BTfjkEV","executionInfo":{"status":"ok","timestamp":1701356070402,"user_tz":-540,"elapsed":15738,"user":{"displayName":"허윤빈","userId":"08770990058347312512"}},"outputId":"c834c914-f454-4de0-c89c-32e65c746940"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('pytorch', 61), ('aws', 48), ('tensorflow', 40), ('git', 38)]\n","[('aws', 17), ('python', 14), ('git', 9), ('linux', 9)]\n","['python', 'sql']\n","['pytorch', 'aws', 'tensorflow', 'git', 'aws', 'git', 'linux']\n","git,linux,pytorch,aws,tensorflow\n","Git을 이용하여 협업 및 버전 관리 능력을 향상시켜보세요.\n","Linux 환경에서 개발을 해보면 다양한 도구와 명령어에 익숙해질 수 있습니다.\n","PyTorch를 사용해 딥러닝 역량을 키워보세요.\n","AWS를 활용하여 클라우드 컴퓨팅 및 인프라 관리 능력을 향상시켜보세요.\n","TensorFlow를 사용하여 머신러닝 역량을 키워보세요.\n"]}]},{"cell_type":"code","source":["output = generate_text('분산환경, 의사결정, 최적화')\n","print(output)"],"metadata":{"id":"MnSA7mPecOw7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701158486354,"user_tz":-540,"elapsed":6503,"user":{"displayName":"허윤빈","userId":"08770990058347312512"}},"outputId":"6e646508-65a9-4686-d0aa-f9c2bf2e2ef0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["분산환경에 대한 역량을 길러보세요. 의사결정과 최적화 역량도 함께 강화해보면 좋을 것 같습니다.\n"]}]}]}